{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras import initializers\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "from IPython.display import Image\n",
    "import plotly.io as pio\n",
    "\n",
    "import time\n",
    "import gc\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/home/egracheva/Work/PolyInfo/DFT properties/LTE_DFT.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the outlier at HOMO=-10\n",
    "data = data[data['HOMO']>-10]\n",
    "# Dropping all the correlated features\n",
    "data = data.drop(['Entropy', 'ZeroPointEn', 'SumEnthal', 'SumFreeEner', 'SumEner'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.iloc[:, 2:-1].values\n",
    "y = data['Linear expansion coefficient'].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_x = StandardScaler()\n",
    "x_scaled = sc_x.fit_transform(x)\n",
    "sc_y = StandardScaler()\n",
    "y_scaled = sc_y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = x_scaled.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_notrain(n_units1, n_units2, n_units3, weight):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(int(n_units1), \n",
    "                    input_dim=int(n_components),\n",
    "                    kernel_initializer=initializers.constant(value=weight), \n",
    "                    activation='relu'))        \n",
    "    if n_units2 != 0:\n",
    "        model.add(Dense(int(n_units2), \n",
    "                        kernel_initializer=initializers.constant(value=weight), \n",
    "                        activation='relu'))\n",
    "    if n_units3 != 0:\n",
    "        model.add(Dense(int(n_units3), \n",
    "                        kernel_initializer=initializers.constant(value=weight), \n",
    "                        activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='glorot_normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss=root_mean_squared_error, optimizer='sgd')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(learning_rate, n_units1, n_units2, n_units3, weight):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(int(n_units1), \n",
    "                    input_dim=int(n_components), \n",
    "                    kernel_initializer=initializers.random_normal(mean=weight, stddev=0.05), \n",
    "                    activation='relu'))        \n",
    "    if n_units2 != 0:\n",
    "        model.add(Dense(int(n_units2), \n",
    "                        kernel_initializer=initializers.random_normal(mean=weight, stddev=0.05), \n",
    "                        activation='relu'))\n",
    "    if n_units3 != 0:\n",
    "        model.add(Dense(int(n_units3), \n",
    "                        kernel_initializer=initializers.random_normal(mean=weight, stddev=0.05), \n",
    "                        activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='glorot_normal'))\n",
    "    # Compile the model\n",
    "    my_adam = Adam(lr=math.pow(10,-float(learning_rate)))\n",
    "    model.compile(loss=root_mean_squared_error, optimizer=my_adam)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split(x, y, random_state=123):\n",
    "\n",
    "    full_idx = np.array([x for x in range(x.shape[0])])\n",
    "    train_idx = np.random.choice(full_idx, \n",
    "                                 size=math.ceil(0.8*x.shape[0]), \n",
    "                                 replace = False)\n",
    "    x_train = x[train_idx]\n",
    "    y_train = y[train_idx].reshape(-1, 1)\n",
    "    \n",
    "    valid_idx = full_idx[np.isin(full_idx, train_idx, invert=True)]\n",
    "    x_valid = x[valid_idx]\n",
    "    y_valid = y[valid_idx].reshape(-1, 1)\n",
    "    \n",
    "    return x_train, x_valid, y_train, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_splits = 10 # 17\n",
    "n_runs = 4\n",
    "best_to_keep = 20\n",
    "rmse_threshold = 5\n",
    "min_kept = 5\n",
    "n_geoms = 3\n",
    "comment = \"const.search+rand.fix.train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rates = [float(ialpha/10.) for ialpha in range(20,40,2)]\n",
    "# batch_sizes = [4, 8, 16, 32, 64, 128]\n",
    "# n_units1_bounds = [2, 4, 8, 12, 16, 24, 32, 64]\n",
    "# n_units2_bounds = [2, 4, 8, 12, 16, 24, 32, 64]\n",
    "# n_units3_bounds = [2, 4, 8, 12, 16, 24, 32, 64]\n",
    "# weight_range = [-0.1, -0.08, -0.06, -0.04, -0.02, 0.02, 0.04, 0.06, 0.08, 0.1]\n",
    "learning_rates = [float(ialpha/10.) for ialpha in range(20,40,10)]\n",
    "batch_sizes = [16, 32]\n",
    "n_units1_bounds = [2, 4, 8]\n",
    "n_units2_bounds = [2, 4, 8]\n",
    "n_units3_bounds = [2, 4, 8]\n",
    "weight_range = [-0.06, 0.06]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\"Runs\":n_runs,\n",
    "            \"Number of splits\":kfold_splits,\n",
    "            \"Phase 1 models kept\":best_to_keep,\n",
    "            \"RMSE threshold\":rmse_threshold,\n",
    "            \"Phase 2 minimum outcome\":min_kept,\n",
    "            \"Learning rates\":learning_rates,\n",
    "            \"First layer\":n_units1_bounds,\n",
    "            \"Second layer\":n_units2_bounds,\n",
    "            \"Third layer\":n_units3_bounds,\n",
    "            \"Comment\":comment\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creation of the directory /home/egracheva/Work/PolyInfo/DFT properties/NN/ENAS/Kept20_RMSEthr5_Min5const.search+rand.fix.train failed\n"
     ]
    }
   ],
   "source": [
    "# detect the current working directory and print it\n",
    "path = os.getcwd()  \n",
    "\n",
    "suffix = \"Kept{}_RMSEthr{}_Min{}{}\".format(best_to_keep, rmse_threshold, min_kept, comment)\n",
    "output_dir = \"{}/NN/ENAS/{}\".format(path, suffix)\n",
    "\n",
    "try:  \n",
    "    os.mkdir(output_dir)\n",
    "except OSError:  \n",
    "    print (\"Creation of the directory %s failed\" % output_dir)\n",
    "else:  \n",
    "    print (\"The directory %s is created\" % output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('{}/Settings.json'.format(output_dir), 'w') as json_file:  \n",
    "    json.dump(settings, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponenial_func(x, a, b, c):\n",
    "    return a*np.exp(-b*x)+c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, I search for the best geometry without training the network, jsut passing the data throu it and seeing the result\n",
    "def geometry_search(x, y, n_units1_bounds, n_units2_bounds, n_units3_bounds):    \n",
    "    \n",
    "    columns = ['n_units1', 'n_units2', 'n_units3', 'mean_rmse', 'best_weight']\n",
    "    geoms = pd.DataFrame()\n",
    "    \n",
    "    for n_units1 in n_units2_bounds:\n",
    "        for n_units2 in n_units2_bounds:\n",
    "            for n_units3 in n_units3_bounds:\n",
    "                #print(\"The neural network parameters are: [{}, {}, {}]\".format(n_units1, n_units2, n_units3))\n",
    "                rmse_scores = []\n",
    "                for weight in weight_range:\n",
    "                    K.clear_session()\n",
    "                    # Create a new model\n",
    "                    model = model_notrain(n_units1, n_units2, n_units3, weight)\n",
    "                    # Evaluate without training\n",
    "                    rmse = model.evaluate(x, y, verbose=0)\n",
    "                    rmse_scores.append(rmse)\n",
    "                    #print(weight, rmse)\n",
    "                mean_rmse = np.mean(rmse)\n",
    "                best_weight = weight_range[np.argmin(rmse)]\n",
    "                geoms = geoms.append([[n_units1, n_units2, n_units3, mean_rmse, best_weight]], ignore_index=True)\n",
    "    geoms.columns = columns\n",
    "    best_geoms = geoms.sort_values(by=\"mean_rmse\").iloc[:n_geoms, :].reset_index(drop=True)\n",
    "    \n",
    "    return best_geoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def each_fold_optimization(x, y, learning_rate, batch_size, n_units1, n_units2, n_units3, weight):\n",
    "\n",
    "    print(\"The neural network parameters are: [{}, {}]\".format(learning_rate, batch_size))\n",
    "    \n",
    "    \n",
    "    full_idx = np.array([x for x in range(x.shape[0])])\n",
    "    train_idx = np.random.choice(full_idx,\n",
    "                                 size=math.ceil(0.8*x.shape[0]),\n",
    "                                 replace = False)\n",
    "    x_train = x[train_idx]\n",
    "    y_train = y[train_idx].reshape(-1, 1)\n",
    "    \n",
    "    valid_idx = full_idx[np.isin(full_idx, train_idx, invert=True)]\n",
    "    x_valid = x[valid_idx]\n",
    "    y_valid = y[valid_idx].reshape(-1, 1)\n",
    "    \n",
    "    x_train, x_valid, y_train, y_valid =random_split(x, y, seed)\n",
    "    \n",
    "    pred_valid_bag = np.zeros((x_valid.shape[0], n_runs))\n",
    "    epochs = np.array([1, 5, 10, 15, 20])\n",
    "    valid_evol = []\n",
    "    for epoch in epochs:\n",
    "        for i in range(n_runs):\n",
    "            K.clear_session()\n",
    "            # Create a new model\n",
    "            model_opt = model_train(learning_rate, n_units1, n_units2, n_units3, weight)\n",
    "            # Callbacks\n",
    "            model_opt.fit(x_train,\n",
    "                          y_train,\n",
    "                          batch_size = batch_size,\n",
    "                          validation_data = (x_valid, y_valid),\n",
    "                          epochs=epoch,\n",
    "                          verbose=0)\n",
    "\n",
    "            # Prediction\n",
    "            pred_valid_bag[:,i] = model_opt.predict(x_valid).ravel()\n",
    "        pred_valid_mean = np.mean(pred_valid_bag, axis = 1)\n",
    "        rmse_valid_epoch = np.sqrt(mean_squared_error(y_valid, pred_valid_mean))\n",
    "        valid_evol.append(rmse_valid_epoch)\n",
    "    valid_evol = np.array(valid_evol)\n",
    "    try:\n",
    "        popt, _ = curve_fit(exponenial_func, epochs, valid_evol)\n",
    "        rmse = np.sqrt(mean_squared_error(valid_evol, exponenial_func(epochs, *popt)))\n",
    "    # In case the exponential failed to fit\n",
    "    except:\n",
    "        print(\"Could not fit the exponential function to the data\")\n",
    "        rmse = np.inf\n",
    "    \n",
    "    score = np.log(rmse) - popt[0]\n",
    "    print(valid_evol)\n",
    "    print(\"RMSE: {0}\".format(rmse))\n",
    "    print(\"A: {0}\".format(popt[0]))\n",
    "    print(\"SCORE:\")\n",
    "    print(score)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************\n",
      "Started fold #0...\n",
      "Geometry search starting...\n",
      "\n",
      "Best 3 geometries:\n",
      "   n_units1  n_units2  n_units3  mean_rmse  best_weight\n",
      "0         8         8         2   0.806223        -0.06\n",
      "1         8         8         8   0.807206        -0.06\n",
      "2         4         8         8   0.807317        -0.06\n",
      "********************************\n",
      "Architecture search starting...\n",
      "\n",
      "Current conf:\n",
      "Number of units in the 1st layer: 8.0\n",
      "Number of units in the 2nd layer: 8.0\n",
      "Number of units in the 3rd layer: 2.0\n",
      "Best weight: -0.06\n",
      "The neural network parameters are: [2.0, 16]\n",
      "[1.09211039 1.10405465 1.05463261 1.0998508  1.10242385]\n",
      "RMSE: 0.01843661537311415\n",
      "A: 0.1715890027777932\n",
      "SCORE:\n",
      "-4.165005628574257\n",
      "The neural network parameters are: [2.0, 32]\n",
      "[1.12240546 1.09387138 1.06793649 1.123052   1.12281464]\n",
      "RMSE: 0.020507590310171166\n",
      "A: 2.895803197076994\n",
      "SCORE:\n",
      "-6.78276339941099\n",
      "The neural network parameters are: [3.0, 16]\n",
      "[1.22961245 1.22880271 1.22570837 1.22838695 1.22836061]\n",
      "RMSE: 0.0010989340994549633\n",
      "A: 2.4574394207606076\n",
      "SCORE:\n",
      "-9.270853990218393\n",
      "The neural network parameters are: [3.0, 32]\n",
      "[0.61465476 0.61415908 0.61364718 0.61350472 0.60922215]\n",
      "RMSE: 0.0017748969718890016\n",
      "A: 1.025587947055776\n",
      "SCORE:\n",
      "-7.359600848801349\n",
      "Current conf:\n",
      "Number of units in the 1st layer: 8.0\n",
      "Number of units in the 2nd layer: 8.0\n",
      "Number of units in the 3rd layer: 8.0\n",
      "Best weight: -0.06\n",
      "The neural network parameters are: [2.0, 16]\n",
      "[1.09879267 1.08291868 1.05618886 1.05670283 1.09798636]\n",
      "RMSE: 0.015587851692612668\n",
      "A: 0.04140978106786994\n",
      "SCORE:\n",
      "-4.202673186821225\n",
      "The neural network parameters are: [2.0, 32]\n",
      "Could not fit the exponential function to the data\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'popt' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-6726774557f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m                                                    \u001b[0mn_units2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_units2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                                                    \u001b[0mn_units3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_units3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                                                    weight = weight)\n\u001b[0m\u001b[1;32m     46\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                         \u001b[0mbest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-0f6a0c0d97ab>\u001b[0m in \u001b[0;36meach_fold_optimization\u001b[0;34m(x, y, learning_rate, batch_size, n_units1, n_units2, n_units3, weight)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrmse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpopt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_evol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RMSE: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'popt' referenced before assignment"
     ]
    }
   ],
   "source": [
    "opt_step = 0\n",
    "n_images = x_scaled.shape[0]\n",
    "kfold = KFold(kfold_splits, shuffle = True)\n",
    "fold = 0\n",
    "\n",
    "folds = np.array(range(0, kfold_splits)) # The folds of the interest\n",
    "\n",
    "best_confs = []\n",
    "\n",
    "for train, test in kfold.split(x_scaled):\n",
    "    if fold in folds:\n",
    "        print(\"********************************\")\n",
    "        print(\"Started fold #{}...\".format(fold))\n",
    "        \n",
    "        x_train_val = x_scaled[train,:]\n",
    "        y_train_val = y_scaled[train,:]    \n",
    "        \n",
    "        # Grid search\n",
    "        best_score = 100 # Some large initial value\n",
    "        \n",
    "        print(\"Geometry search starting...\\n\")\n",
    "        best_geoms = geometry_search(x_train_val, y_train_val, n_units1_bounds, n_units2_bounds, n_units3_bounds)\n",
    "        print(\"Best {} geometries:\".format(n_geoms))\n",
    "        print(best_geoms)\n",
    "        \n",
    "        print(\"********************************\")\n",
    "        print(\"Architecture search starting...\\n\")\n",
    "        \n",
    "        for _, geom in best_geoms.iterrows():\n",
    "            n_units1, n_units2, n_units3, _, weight = geom\n",
    "            print(\"Current conf:\")\n",
    "            print(\"Number of units in the 1st layer: {}\".format(n_units1))\n",
    "            print(\"Number of units in the 2nd layer: {}\".format(n_units2))\n",
    "            print(\"Number of units in the 3rd layer: {}\".format(n_units3))\n",
    "            print(\"Best weight: {}\".format(weight))\n",
    "            for learning_rate in learning_rates:\n",
    "                for batch_size in batch_sizes:                    \n",
    "                    score = each_fold_optimization(x = x_train_val, \n",
    "                                                   y = y_train_val, \n",
    "                                                   learning_rate = learning_rate, \n",
    "                                                   batch_size = batch_size, \n",
    "                                                   n_units1 = n_units1, \n",
    "                                                   n_units2 = n_units2, \n",
    "                                                   n_units3 = n_units3, \n",
    "                                                   weight = weight)\n",
    "                    if score < best_score: \n",
    "                        best_score = score\n",
    "                        best_conf = [n_units1, n_units2, n_units3, learning_rate, batch_size]\n",
    "                        \n",
    "        print(\"Best score: \" + str(best_score))\n",
    "        print(\"Best configuration: \" + str(best_conf))\n",
    "\n",
    "        best_confs.append(best_conf)\n",
    "        pd.DataFrame(best_confs).to_csv(\"{}/Best_configurations.csv\".format(output_dir))\n",
    "        \n",
    "        del x_train_val\n",
    "        del y_train_val\n",
    "        gc.collect()\n",
    "        \n",
    "        print(\"Finished the \" + str(fold) + \" fold\")\n",
    "        print(\"----------------------------------------------------\")\n",
    "        fold += 1\n",
    "    else:   \n",
    "        print(\"Skipped the \" + str(fold) + \" fold\")\n",
    "        print(\"----------------------------------------------------\")  \n",
    "        fold += 1\n",
    "        best_confs.append([0,0,0,0,0])\n",
    "        pd.DataFrame(best_confs).to_csv(\"{}/Best_configurations.csv\".format(output_dir))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_confs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def each_fold_prediction(x_train, x_valid, learning_rate, n_units1, n_units2, n_units3, batch_size):\n",
    "    \n",
    "    prediction_train_bag = np.zeros((x_train.shape[0], n_runs))\n",
    "    prediction_valid_bag = np.zeros((x_valid.shape[0], n_runs))\n",
    "    #prediction_test_bag = np.zeros((x_test.shape[0], n_runs))\n",
    "    \n",
    "    rmse_train = np.zeros((n_runs, 1))\n",
    "    rmse_valid = np.zeros((n_runs, 1))\n",
    "    score = np.zeros((n_runs, 1))\n",
    "    \n",
    "    print(\"Running for the prediction...\")\n",
    "    for i in range(n_runs):\n",
    "        if i%1==0:\n",
    "            print(str(i) + \" runs are done\")\n",
    "        \n",
    "        model_final = model_train(learning_rate, n_units1, n_units2, n_units3, weight)\n",
    "        model_final.fit(x_train, \n",
    "                        y_train, \n",
    "                        batch_size = batch_size, \n",
    "                        validation_data = (x_valid, y_valid), \n",
    "                        epochs=150, \n",
    "                        verbose = 0)\n",
    "        # Prediction\n",
    "        prediction_train_bag[:,i] = model_final.predict(x_train).ravel()\n",
    "        prediction_valid_bag[:,i] = model_final.predict(x_valid).ravel()\n",
    "        #prediction_test_bag[:,i] = model_final.predict(x_test).ravel()\n",
    "                \n",
    "        rmse_train[i] = np.sqrt(mean_squared_error(y_train, prediction_train_bag[:, i]))\n",
    "        rmse_valid[i] = np.sqrt(mean_squared_error(y_valid, prediction_valid_bag[:, i]))\n",
    "        score[i] = rmse_valid[i]/rmse_train[i]\n",
    "        \n",
    "        # Cleaning up\n",
    "        ! rm -rf /tmp/weights_int.hdf5\n",
    "        K.clear_session()\n",
    "        del model_final\n",
    "    \n",
    "    # The outputs are all scaled (need to be unscaled)\n",
    "    return prediction_train_bag, prediction_val_bag, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_step = 0\n",
    "n_images = X_data_scaled_pca.shape[0]\n",
    "kfold = KFold(kfold_splits, shuffle = False)\n",
    "fold = 0\n",
    "folds = np.array(range(0,kfold_splits)) # The folds of the interest\n",
    "\n",
    "for train_valid, test in kfold.split(X_data_scaled_pca):\n",
    "    if fold in folds:\n",
    "        print(\"Started the \" + str(fold) + \" fold...\")\n",
    "        \n",
    "        ceiling = int(0.9*len(train_val))\n",
    "        train = train_valid[:ceiling]\n",
    "        valid = train_valid[ceiling:]\n",
    "        \n",
    "        x_train, x_valid = x_scaled[train,:], x_scaled[valid,:]\n",
    "        y_train, y_valid = y_scaled[train,:], y_scaled[valid,:]\n",
    "        \n",
    "        n_units1, n_units2, n_units3, learning_rate, batch_size = best_confs[fold]\n",
    "        prediction_train_bag, prediction_val_bag, score = \\\n",
    "                              each_fold_prediction(x_train, x_valid, learning_rate, n_units1, n_units2, n_units3, batch_size)\n",
    "\n",
    "        train_predictions = prediction_train_bag[:, np.array(score<rmse_threshold).ravel()]\n",
    "        valid_predictions = prediction_val_bag[:, np.array(score<rmse_threshold).ravel()]\n",
    "        #test_predictions = prediction_test_bag[:, np.array(score<rmse_threshold).ravel()]\n",
    "\n",
    "        #pd.DataFrame(test_predictions).to_csv(\"{}/Test_predictions_fold{}.csv\".format(output_dir, fold), index = False, header = False)\n",
    "        pd.DataFrame(valid_predictions).to_csv(\"{}/Validation_predictions_fold{}.csv\".format(output_dir, fold), index = False, header = False)       \n",
    "        pd.DataFrame(train_predictions).to_csv(\"{}/Train_predictions_fold{}.csv\".format(output_dir, fold), index = False, header = False)\n",
    "        \n",
    "        mean_train_predictions = np.mean(train_predictions, axis=1)\n",
    "        mean_valid_predictions = np.mean(valid_predictions, axis=1)\n",
    "        sigma_train_predictions = np.std(train_predictions, axis=1)\n",
    "        sigma_valid_predictions = np.std(valid_predictions, axis=1)\n",
    "        \n",
    "        rmse_train = mean_squared_error(y_train, mean_train_predictions)\n",
    "        rmse_valid = mean_squared_error(y_valid, mean_valid_predictions)\n",
    "        r2_train = r2_score(y_train, mean_train_predictions)\n",
    "        r2_valid = r2_score(y_valid, mean_valid_predictions)\n",
    "        mae_train = mean_absolute_error(y_train, mean_train_predictions)\n",
    "        mae_valid = mean_absolute_error(y_valid, mean_valid_predictions)\n",
    "        \n",
    "        print(\"Fold #{0}:\".format(fold))\n",
    "        print(\"RMSE train, valid: {0:0.4f}, {1:0.4f}\".format(rmse_train, rmse_valid))\n",
    "        print(\"MAE train, valid: {0:0.4f}, {1:0.4f}\".format(mae_train, mae_valid))\n",
    "        print(\"R2 score train, valid: {0:0.4f}, {1:0.4f}\".format(r2_train, r2_valid))\n",
    "        \n",
    "        \n",
    "        # ~~~~~~~~~~~~~~~~~~PLOTS~~~~~~~~~~~~~~~~~~~~\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        # Setting plot limits\n",
    "        y_true_min = min(np.min(y_train), np.min(y_valid))#, np.min(y_test))\n",
    "        y_true_max = max(np.max(y_train), np.max(y_valid))#, np.max(y_test))\n",
    "        y_pred_min = min(np.min(mean_train_predictions), np.min(mean_valid_predictions))#, np.min(y_test_pred))\n",
    "        y_pred_max = max(np.max(mean_train_predictions), np.max(mean_valid_predictions))#, np.max(y_test_pred))\n",
    "\n",
    "        axmin = y_true_min-0.1*(y_true_max-y_true_min)\n",
    "        axmax = y_true_max+0.1*(y_true_max-y_true_min)\n",
    "        aymin = y_pred_min-0.1*(y_pred_max-y_pred_min)\n",
    "        aymax = y_pred_max+0.1*(y_pred_max-y_pred_min)\n",
    "\n",
    "        plt.xlim(min(axmin, aymin), max(axmax, aymax))\n",
    "        plt.ylim(min(axmin, aymin), max(axmax, aymax))\n",
    "        \n",
    "        plt.errorbar(y_train, \n",
    "                    mean_train_predictions,\n",
    "                    yerr = sigma_train_predictions,\n",
    "                    fmt='o',\n",
    "                    label=\"Train\",\n",
    "                    elinewidth = 1, \n",
    "                    ms=7,\n",
    "                    mfc='#7cb2cc',\n",
    "                    markeredgewidth = 0,\n",
    "                    alpha=0.7)\n",
    "        plt.errorbar(y_valid, \n",
    "                    mean_valid_predictions,\n",
    "                    yerr = sigma_valid_predictions,\n",
    "                    elinewidth = 1,\n",
    "                    fmt='o',\n",
    "                    label=\"Validation\", \n",
    "                    ms=7, \n",
    "                    mfc='#f4a582',\n",
    "                    markeredgewidth = 0,\n",
    "                    alpha=0.7)\n",
    "        # Plot X=Y line\n",
    "        plt.plot([max(plt.xlim()[0], plt.ylim()[0]), \n",
    "                  min(plt.xlim()[1], plt.ylim()[1])],\n",
    "                 [max(plt.xlim()[0], plt.ylim()[0]), \n",
    "                  min(plt.xlim()[1], plt.ylim()[1])],\n",
    "                 ':', color = '#595f69')\n",
    "        \n",
    "        plt.xlabel('Observations LTE', fontsize = 12)\n",
    "        plt.ylabel('Predictions LTE', fontsize = 12)\n",
    "        plt.legend()\n",
    "        # ~~~~~~~~~~~~~~~~~~CHANGED HERE~~~~~~~~~~~~~~~~~~~~\n",
    "        # Added fold number\n",
    "        plt.savefig(\"{}/Plot_predictions_fold{}.png\".format(output_dir, fold)', bbox_inches='tight', dpi=80)\n",
    "        plt.close()\n",
    "        \n",
    "        del x_train, x_valid\n",
    "        del y_train, y_valid\n",
    "        gc.collect()\n",
    "        \n",
    "        print(\"Finished the \" + str(fold) + \" fold\")\n",
    "        print(\"----------------------------------------------------\")\n",
    "        fold += 1\n",
    "    else:   \n",
    "        print(\"Skipped the \" + str(fold) + \" fold\")\n",
    "        print(\"----------------------------------------------------\")  \n",
    "        fold += 1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = [0, 3, 6, 34, 2, 77, 14, 47]\n",
    "pred = [2, 6, 7, 38, 4, 64, 13, 53]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = [0.1, 0.2, 0.2, 10, 0.5, 5, 2, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ceiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_val[:ceiling]\n",
    "val = train_val[ceiling:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[:50]\n",
    "test_data = data[50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prediction_test = np.zeros((n_images, 1))\n",
    "final_std_test = np.zeros((n_images, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in range(17):\n",
    "    print(f)\n",
    "    test_fold = pd.read_csv(\"./Test_predictions_fold{}_PCA20_2step_5min_rmseratio5_yields5.csv\".format(f), sep=\",\", header = None).values \n",
    "\n",
    "    # Getting rid of first zeros\n",
    "    #test_fold = test_fold[:,1:50]\n",
    "    \n",
    "    final_prediction_test[f*5:f*5+5] = np.mean(sc_y.inverse_transform(test_fold), axis = 1).reshape((5,1))\n",
    "    final_std_test[f*5:f*5+5] = np.std(sc_y.inverse_transform(test_fold), axis = 1).reshape((5,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(Y_data, final_prediction_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ialpha in range(0,10,3):\n",
    "    print(ialpha)\n",
    "    print(ialpha/10.)\n",
    "    b = ialpha/10.\n",
    "    print(10.**-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [10**(float(-1*ialpha/10)) for ialpha in range(10,20,1)]\n",
    "b = [10**(float(-1*ialpha/10)) for ialpha in range(20,25,2)]\n",
    "\n",
    "train = []\n",
    "valid = []\n",
    "score = []\n",
    "color = []\n",
    "for i, a_i in enumerate(a):\n",
    "    for j , a_j in enumerate(a):\n",
    "        for n, b_n in enumerate(b):\n",
    "            for m, b_m in enumerate(b):\n",
    "                train.append(a_i)\n",
    "                valid.append(a_j)\n",
    "                color.append(b_m+b_n)\n",
    "    #         if a_j/a_i>5 or a_j<a_i*0.8:\n",
    "    #             score_i = 1\n",
    "    #         else:\n",
    "    #             score_i = 0\n",
    "                score_i = np.log(np.abs(a_j-a_i)*(b_m+b_n))\n",
    "                score.append(score_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import plot\n",
    "\n",
    "myplot=go.Scatter3d(x=train, \n",
    "                    y=valid, \n",
    "                    z=score,\n",
    "                    mode='markers',\n",
    "                    marker=dict(\n",
    "                        size=5,\n",
    "                        color=color,\n",
    "                        colorscale='Viridis',\n",
    "                        opacity=0.8\n",
    "                        )\n",
    "                   )\n",
    "\n",
    "fig = go.Figure(data=[myplot])\n",
    "\n",
    "fig.layout.update(scene = dict(\n",
    "                    xaxis_title='TRAIN',\n",
    "                    yaxis_title='VALID',\n",
    "                    zaxis_title='SCORE')\n",
    "                 )\n",
    "\n",
    "plot(fig, filename='myplot.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "trace = dict(\n",
    "        name = name,\n",
    "        x = train, y = valid, z = score,\n",
    "        type = \"scatter3d\",    \n",
    "        mode = 'markers',\n",
    "        marker = dict( size=3, color=color, line=dict(width=0) ) )\n",
    "data.append( trace )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
